{"cells":[{"cell_type":"markdown","metadata":{"id":"eVvbsVxL-_5H"},"source":["This notebook contains a Finetuned BERT from Huggingface\n","\n","BERT Paper: https://arxiv.org/pdf/1810.04805.pdf"]},{"cell_type":"markdown","metadata":{"id":"q01on49f_Flw"},"source":["### Library Installations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"L45M0fE43-qc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bertviz\n","  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n","Collecting captum\n","  Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting boto3 (from bertviz)\n","  Downloading boto3-1.34.86-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.31.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2023.12.25)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bertviz) (0.1.99)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: tokenizers\u003c0.19,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.1)\n","Requirement already satisfied: urllib3\u003e=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1-\u003etorchtext) (2.0.7)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n","Collecting botocore\u003c1.35.0,\u003e=1.34.86 (from boto3-\u003ebertviz)\n","  Downloading botocore-1.34.86-py3-none-any.whl (12.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath\u003c2.0.0,\u003e=0.7.1 (from boto3-\u003ebertviz)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer\u003c0.11.0,\u003e=0.10.0 (from boto3-\u003ebertviz)\n","  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch) (2.1.5)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ecaptum) (1.2.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ecaptum) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ecaptum) (4.51.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ecaptum) (1.4.5)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ecaptum) (9.4.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ecaptum) (3.1.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003ecaptum) (2.8.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ebertviz) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ebertviz) (3.6)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ebertviz) (2024.2.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch) (1.3.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib-\u003ecaptum) (1.16.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, boto3, captum, bertviz\n","Successfully installed bertviz-1.4.0 boto3-1.34.86 botocore-1.34.86 captum-0.7.0 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 s3transfer-0.10.1\n"]}],"source":["!pip install bertviz transformers torch torchtext tqdm captum"]},{"cell_type":"markdown","metadata":{"id":"j3y-6ANc_HxX"},"source":["### Library Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lXbkp5-i_JGo"},"outputs":[],"source":["from google.colab import drive\n","from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, get_scheduler, Trainer, TrainingArguments\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn import metrics\n","from tqdm.auto import tqdm\n","from captum.attr import visualization as viz\n","from captum.attr import LayerConductance, LayerIntegratedGradients\n","import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import datetime"]},{"cell_type":"markdown","metadata":{"id":"cqacqaUXBNTg"},"source":["### Folder Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sajxGjMVBP3o"},"outputs":[],"source":["BERT_MODEL = 'bert-base-uncased'\n","FOLDER_PATH = '/content/drive/MyDrive/cs4248/'\n","DATASET_PATH = os.path.join(FOLDER_PATH, 'datasets')\n","ORIGINAL_DATASET_PATH = os.path.join(DATASET_PATH, 'lun_dataset_original')\n","ORIGINAL_TEST_DATASET_FILE_NAME = 'test_final_with_topics_new.csv'\n","MIXED_DATASET_PATH = os.path.join(DATASET_PATH, 'lun_dataset_modified')\n","MIXED_DATASET_TRAIN_FILE_NAME = 'merged_final_df_with_topics_new.csv'\n","TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","MODEL_SAVE_PATH = os.path.join(FOLDER_PATH, 'models', BERT_MODEL, TIMESTAMP)"]},{"cell_type":"markdown","metadata":{"id":"EzbX39S8rSCO"},"source":["### Device Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e8p9_QnOrYxS"},"outputs":[],"source":["TORCH_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","torch.set_default_device(TORCH_DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"1fXz4vTAAz_m"},"source":["### Mount Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oScI49Z2A4C2"},"outputs":[],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEmHFHdABLYX"},"outputs":[],"source":["# Create folder if does not exist\n","dir_paths = [FOLDER_PATH, ORIGINAL_DATASET_PATH, MIXED_DATASET_PATH, MODEL_SAVE_PATH]\n","for dir_path in dir_paths:\n","  if not os.path.exists(dir_path):\n","    os.makedirs(dir_path)"]},{"cell_type":"markdown","metadata":{"id":"C2-A466HCW8Y"},"source":["### Prepare Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tClvyAjNCY1d"},"outputs":[],"source":["train_dataframe = pd.read_csv(os.path.join(MIXED_DATASET_PATH, MIXED_DATASET_TRAIN_FILE_NAME))\n","# train_dataframe = pd.read_csv(os.path.join(ORIGINAL_DATASET_PATH, 'fulltrain.csv'), names=[\"label\", \"text\"])\n","test_dataframe = pd.read_csv(os.path.join(MIXED_DATASET_PATH, ORIGINAL_TEST_DATASET_FILE_NAME))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CjA_EjgqOzSK"},"outputs":[],"source":["print(\"Original Training Dataframe\")\n","train_dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UUQS92dv8yL5"},"outputs":[],"source":["print(\"Test Dataframe\")\n","test_dataframe"]},{"cell_type":"markdown","metadata":{"id":"Jss6eoVMP-0x"},"source":["### Model Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22fzxCRhQB5T"},"outputs":[],"source":["TOKEN_MAX_LENGTH = 512\n","TRAIN_BATCH_SIZE = 8\n","TEST_BATCH_SIZE = 8\n","EPOCHS = 3\n","LEARNING_RATE = 3e-5\n","N_CLASSES = len(set(train_dataframe['label']))"]},{"cell_type":"markdown","metadata":{"id":"Xku1BRkRAsVY"},"source":["### Prepare Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Tr7PoW1At7D"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)"]},{"cell_type":"markdown","metadata":{"id":"frUoftw0QdxM"},"source":["### Prepare Model Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KOHeVOe0QgOk"},"outputs":[],"source":["# LUN Dataset Class\n","class BertLUNDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        text = self.data.text[index]\n","        label = self.data.label[index] - 1  # Subtract 1 to map indices to range [0, num_classes-1]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_token_type_ids=False,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0T8mRHuUvzL"},"outputs":[],"source":["# Prepare Train Dataloader\n","training_dataset = BertLUNDataset(train_dataframe, tokenizer, TOKEN_MAX_LENGTH)\n","train_dataloader = DataLoader(training_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, generator=torch.Generator(device=TORCH_DEVICE))\n","test_dataset = BertLUNDataset(test_dataframe, tokenizer, TOKEN_MAX_LENGTH)\n","test_dataloader = DataLoader(test_dataset, batch_size=TRAIN_BATCH_SIZE, generator=torch.Generator(device=TORCH_DEVICE))"]},{"cell_type":"markdown","metadata":{"id":"Fyn5NlhRnzVt"},"source":["### Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvJLRE8IZUHP"},"outputs":[],"source":["bert_config = BertConfig.from_pretrained(BERT_MODEL, output_hidden_states=True, output_attentions=True, num_labels=N_CLASSES)\n","model = BertForSequenceClassification.from_pretrained(BERT_MODEL, config=bert_config)\n","model"]},{"cell_type":"markdown","metadata":{"id":"jLy2AUIhppTY"},"source":["### Declare Loss Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ibk8EdytprTo"},"outputs":[],"source":["def criterion(outputs, targets):\n","  return nn.CrossEntropyLoss()(outputs, targets)"]},{"cell_type":"markdown","metadata":{"id":"1AwzVE5-qRoE"},"source":["### Declare Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ox8XF0EqSzs"},"outputs":[],"source":["optimizer = torch.optim.Adam(params = model.parameters(),  lr=LEARNING_RATE)"]},{"cell_type":"markdown","metadata":{"id":"iu4dXX3aBX2E"},"source":["### Declare Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZhGvUqlBZOs"},"outputs":[],"source":["num_training_steps = EPOCHS * len(train_dataloader)\n","scheduler = get_scheduler(\n","    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",")"]},{"cell_type":"markdown","metadata":{"id":"BrujGBiaqhbZ"},"source":["### Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBlEtOdad4cx"},"outputs":[],"source":["from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","\n","def train_epoch(model, data_loader, loss_fn, optimizer, device):\n","    model.train()\n","    losses = []\n","    correct_predictions = 0\n","    total_samples = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with tqdm(total=len(data_loader), desc='Training') as pbar:\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","\n","            _, preds = torch.max(outputs.logits, dim=1)\n","            correct_predictions += torch.sum(preds == labels)\n","            total_samples += labels.size(0)\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","            loss = loss_fn(outputs.logits, labels)\n","            losses.append(loss.item())\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            pbar.update(1)\n","\n","    train_f1 = f1_score(all_labels, all_preds, average='weighted')\n","    return correct_predictions.double() / total_samples, sum(losses) / len(losses), train_f1\n","\n","def eval_model(model, data_loader, loss_fn, device):\n","    model.eval()\n","    losses = []\n","    correct_predictions = 0\n","    total_samples = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        with tqdm(total=len(data_loader), desc='Evaluation') as pbar:\n","            for batch in data_loader:\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                labels = batch['label'].to(device)\n","\n","                outputs = model(input_ids, attention_mask=attention_mask)\n","\n","                _, preds = torch.max(outputs.logits, dim=1)\n","                correct_predictions += torch.sum(preds == labels)\n","                total_samples += labels.size(0)\n","\n","                all_preds.extend(preds.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","\n","                loss = loss_fn(outputs.logits, labels)\n","                losses.append(loss.item())\n","\n","                pbar.update(1)\n","\n","    val_f1 = f1_score(all_labels, all_preds, average='weighted')\n","    return correct_predictions.double() / total_samples, sum(losses) / len(losses), val_f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oRCBDUW2qigN"},"outputs":[],"source":["# Training loop\n","for epoch in range(EPOCHS):\n","\n","    print(f'Epoch {epoch + 1}/{EPOCHS}')\n","    # Training\n","    train_acc, train_loss, train_f1 = train_epoch(model, train_dataloader, criterion, optimizer, TORCH_DEVICE)\n","\n","    # Evaluation\n","    val_acc, val_loss, val_f1 = eval_model(model, test_dataloader, criterion, TORCH_DEVICE)\n","\n","    # Print progress\n","\n","\n","    print(f'Train Accuracy: {train_acc:.4f}, Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f}')\n","    print(f'Val Accuracy: {val_acc:.4f}, Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"ycMpCo2u8ONB"},"source":["### Test the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdZLA4wm8Lfp"},"outputs":[],"source":["model.eval()\n","prediction_outputs = []\n","with torch.no_grad():\n","    with tqdm(total=len(test_dataloader), desc='Evaluation') as pbar:\n","      for batch in test_dataloader:\n","        input_ids = batch['input_ids'].to(TORCH_DEVICE)\n","        attention_mask = batch['attention_mask'].to(TORCH_DEVICE)\n","        labels = batch['label'].to(TORCH_DEVICE)\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        _, preds = torch.max(outputs.logits, dim=1)\n","        for index in range(labels.size(0)):\n","          text = tokenizer.decode(input_ids[index])\n","          label = labels[index]\n","          pred = preds[index]\n","          prediction_outputs.append((text, label.item(), pred.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZRa13xFqlrB"},"outputs":[],"source":["pred_df = pd.DataFrame(prediction_outputs, columns=['text', 'true_label', 'pred_label'])\n","pred_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fLYnoIcEruIr"},"outputs":[],"source":["pred_df.to_csv(os.path.join(MODEL_SAVE_PATH, 'predictions.csv'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zUy-fcfYt5iB"},"outputs":[],"source":["y_true = pred_df['true_label']\n","y_pred = pred_df['pred_label']\n","f1_micro= metrics.f1_score(y_true, y_pred, average='micro')\n","f1_macro= metrics.f1_score(y_true, y_pred, average='macro')\n","accuracy = metrics.accuracy_score(y_true, y_pred)\n","print(f\"Accuracy Score = {accuracy}\")\n","print(f\"F1 Score (Micro) = {f1_micro}\")\n","print(f\"F1 Score (Macro) = {f1_macro}\")"]},{"cell_type":"markdown","metadata":{"id":"VgPiVw7H5bjl"},"source":["### Save the model and tokenizer weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G4JjgZN88vWS"},"outputs":[],"source":["tokenizer.save_pretrained(MODEL_SAVE_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DaFA7V_LOYF"},"outputs":[],"source":["# Reference: https://github.com/huggingface/transformers/issues/7849\n","torch.save({\n","    'model_state_dict': model.state_dict(),\n","    'optimizer_state_dict': optimizer.state_dict()\n","}, os.path.join(MODEL_SAVE_PATH, 'bert_model_optim.pth'))\n","\n","torch.save(model, os.path.join(MODEL_SAVE_PATH, 'model.pth'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5fo5yB2itAk"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMW3oIYnJ2DGXLwVRa2Qtfx","collapsed_sections":["q01on49f_Flw","j3y-6ANc_HxX","EzbX39S8rSCO","1fXz4vTAAz_m","Xku1BRkRAsVY"],"gpuType":"V100","name":"","provenance":[{"file_id":"1EiTXL66uEldPvLJEmuAKQL0bP5Pi1Jtu","timestamp":1712826045305}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}