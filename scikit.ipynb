{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Notebook to train XGBoost model on both the original and augmented dataset\n",
    "\n",
    "Here, we use the xgboost package but use the classifier built in the package that is built to integrate with sklearn at the cost of some functionality.\n",
    "[Source](https://www.datacamp.com/tutorial/xgboost-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack, csr_matrix, vstack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure NLTK if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # obtained from https://gist.github.com/susanli2016/d35def30b99f0e2f56c0e01e19ad0878\n",
    "# def gettop_n_bigram(corpus, n=None):\n",
    "#     vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n",
    "#     bag_of_words = vec.transform(corpus)\n",
    "#     sum_words = bag_of_words.sum(axis=0)\n",
    "#     words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "#     words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "#     return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len(row):\n",
    "    return len(row['Text'])\n",
    "\n",
    "def get_len_aug(row):\n",
    "    return len(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature engineering on the dataset\n",
    "def feature_engineering(dataset, aug):\n",
    "    if (aug):\n",
    "        dataset['los'] = dataset.apply(get_len_aug, axis=1)\n",
    "    else:\n",
    "        dataset['los'] = dataset.apply(get_len, axis=1)\n",
    "\n",
    "    # bow_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
    "    # col_name = \"\"\n",
    "    # if aug:\n",
    "    #     col_name = 'text'\n",
    "    # else:\n",
    "    #     col_name = 'Text'\n",
    "    # text_col = dataset[col_name]\n",
    "    # new_col = bow_vectorizer.fit_transform(text_col)\n",
    "    # dataset['bowvec'] = new_col\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features has_swear_word, severity, topic to the augmented train set\n",
    "\n",
    "def add_aug_features(dataframe, x_train):\n",
    "    # Prepare a df with only the features we want to OHE\n",
    "    ohe_df = dataframe[['has_swear_word', 'severity', 'topic']]\n",
    "    encoded_df = pd.get_dummies(ohe_df)\n",
    "    encoded_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "59790    4\n",
       "59791    4\n",
       "59792    4\n",
       "59793    4\n",
       "59794    4\n",
       "Name: label, Length: 59795, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_original = pd.read_csv('dataset/fulltrain.csv')\n",
    "train_augment = pd.read_csv('dataset/merged_final_df_with_topics_new.csv')\n",
    "test_original = pd.read_csv('dataset/balancedtest.csv')\n",
    "test_augment = pd.read_csv('dataset/test_final_with_topics_new.csv')\n",
    "\n",
    "bow_vectorizer_ori = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
    "bow_vectorizer_aug = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
    "# X_ori = bow_vectorizer_ori.fit_transform(train_original['Text'])\n",
    "# X_aug = bow_vectorizer_aug.fit_transform(train_augment['text'])\n",
    "\n",
    "# y_ori = train_original['Label']\n",
    "# y_aug = train_augment['label']\n",
    "\n",
    "X_train_ori = bow_vectorizer_ori.fit_transform(train_original['Text'])\n",
    "X_train_aug = bow_vectorizer_aug.fit_transform(train_augment['text'])\n",
    "\n",
    "y_train_ori = train_original['Label']\n",
    "y_train_aug = train_augment['label']\n",
    "\n",
    "X_test_ori = bow_vectorizer_ori.transform(test_original['Text'])\n",
    "X_test_aug = bow_vectorizer_aug.transform(test_augment['text'])\n",
    "\n",
    "y_test_ori = test_original['Label']\n",
    "y_test_aug = test_augment['label']\n",
    "\n",
    "# X_train_ori, X_test_ori, y_train_ori, y_test_ori = train_test_split(X_ori, y_ori, test_size=0.20, random_state=42)\n",
    "# X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(X_aug, y_aug, test_size=0.20, random_state=42)\n",
    "train_augment['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<59795x228982 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10614690 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<3000x228919 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 549286 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ohe_df = train_augment[['has_swear_word', 'severity', 'topic']]\n",
    "encoded_df = pd.get_dummies(train_augment, columns = ['has_swear_word', 'severity', 'topic'])\n",
    "dropped_df = encoded_df.drop(['label', 'text', 'processed_text'], axis=1)\n",
    "sparse = csr_matrix(dropped_df)\n",
    "sparse_2 = csr_matrix(X_train_aug)\n",
    "X_train_combined = hstack([sparse_2, sparse])\n",
    "\n",
    "encoded_df = pd.get_dummies(test_augment, columns = ['has_swear_word', 'severity', 'topic'])\n",
    "dropped_df = encoded_df.drop(['label', 'text', 'processed_text'], axis=1)\n",
    "sparse = csr_matrix(dropped_df)\n",
    "sparse_2 = csr_matrix(X_test_aug)\n",
    "X_test_combined = hstack([sparse_2, sparse])\n",
    "\n",
    "display(X_train_combined)\n",
    "display(X_test_combined)\n",
    "\n",
    "def pad_columns(matrix1, matrix2):\n",
    "    matrix1_rows = matrix1.shape[0]\n",
    "    matrix2_rows = matrix2.shape[0]\n",
    "    matrix1_cols = matrix1.shape[1]\n",
    "    matrix2_cols = matrix2.shape[1]\n",
    "    diff = matrix1_cols - matrix2_cols\n",
    "    if (diff < 0):\n",
    "        # Need to pad columns to matrix 1\n",
    "        diff = diff * -1\n",
    "        zero_matrix = csr_matrix((matrix1_rows, diff))\n",
    "        matrix1 = hstack([matrix1, zero_matrix])\n",
    "    elif (diff > 0):\n",
    "        # Need to pad columns to matrix 2\n",
    "        zero_matrix = csr_matrix((matrix2_rows, diff))\n",
    "        matrix2 = hstack([matrix2, zero_matrix])\n",
    "    return (matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 228864)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(59795, 228864)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run this if you need to modify X_train again for some reason\n",
    "# X_train = train_augment['topic']\n",
    "# print(dropped_df)\n",
    "display(X_test_aug.shape)\n",
    "display(X_train_aug.shape)\n",
    "# print(X_test_ori.shape)\n",
    "# print(train_original[:5])\n",
    "# print(test_original[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] END ...................................n_estimators=700; total time= 1.6min\n",
      "[CV] END ...................................n_estimators=700; total time= 1.6min\n",
      "[CV] END ...................................n_estimators=800; total time= 1.8min\n",
      "[CV] END ...................................n_estimators=800; total time= 1.8min\n",
      "[CV] END ...................................n_estimators=900; total time= 2.0min\n",
      "[CV] END ...................................n_estimators=900; total time= 2.1min\n",
      "optimal_param:  700\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for xgb model\n",
    "\n",
    "# First, we do a train_test_split on the original dataset\n",
    "bow_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
    "X_ori = bow_vectorizer.fit_transform(train_original['Text'])\n",
    "y_ori = train_original['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ori, y_ori, test_size=0.20, random_state=42)\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', tree_method='hist', enable_categorical=True, max_depth=3, n_estimators=500)\n",
    "# params = {'n_estimators': [1, 10, 25, 50, 100, 200], 'eta': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'max_depth': [2, 3, 4, 5, 10, 20]}\n",
    "params = {'n_estimators': [700, 800 ,900]}\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "# Yes this is probably not enough, but the dataset is large, and I don't have all day.\n",
    "cv = RepeatedKFold(n_splits=2, n_repeats=1)\n",
    "\n",
    "clf = GridSearchCV(xgb_classifier, params, cv=cv, verbose=2)\n",
    "xgb_opt = clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"optimal_param: \", xgb_opt.best_estimator_.get_params()['n_estimators'])\n",
    "# print(\"optimal_param: \", xgb_opt.best_estimator_.get_params()['eta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning notes\n",
    "For the XGBoost model, I decided to stick to tree ensemble methods (might need to justify, but it is the default so it is probably the more general one). Hence, there are 3 main hyperparameters to tune:  \n",
    "1. n_estimators: Number of estimators used in the ensemble model.\n",
    "1. eta: The learning rate.\n",
    "1. max_depth: The maximum depth of each individual tree model.\n",
    "\n",
    "Hyperparameter tuning was done on the training data with an 80:20 test split. Sklearn's GridSearchCV was used to automate the process.\n",
    "In the end, the values of the hyperparameters we arrived at was:\n",
    "1. n_estimators: 700\n",
    "1. eta: 0.5\n",
    "1. max_depth: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.70       750\n",
      "           1       0.71      0.52      0.60       750\n",
      "           2       0.55      0.50      0.52       750\n",
      "           3       0.66      0.92      0.77       750\n",
      "\n",
      "    accuracy                           0.66      3000\n",
      "   macro avg       0.66      0.66      0.65      3000\n",
      "weighted avg       0.66      0.66      0.65      3000\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 228982, got 228919",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Augmented dataset\u001b[39;00m\n\u001b[1;32m     18\u001b[0m xgb_classifier\u001b[38;5;241m.\u001b[39mfit(X_train_combined, y_train_aug)\n\u001b[0;32m---> 19\u001b[0m y_pred_aug \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAugmented dataset:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test_aug, y_pred_aug))\n",
      "File \u001b[0;32m~/Desktop/Year_4_Sem_2/CS4248/4248_project_Dissect_LUN/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1553\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1546\u001b[0m     X: ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m-> 1553\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[1;32m   1561\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[0;32m~/Desktop/Year_4_Sem_2/CS4248/4248_project_Dissect_LUN/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Year_4_Sem_2/CS4248/4248_project_Dissect_LUN/.venv/lib/python3.10/site-packages/xgboost/core.py:2428\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2425\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2426\u001b[0m         )\n\u001b[1;32m   2427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m-> 2428\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2429\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2430\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2431\u001b[0m         )\n\u001b[1;32m   2433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 228982, got 228919"
     ]
    }
   ],
   "source": [
    "# Tuned model\n",
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', tree_method='hist', enable_categorical=True, max_depth = 5, n_estimators=700, eta=0.5)\n",
    "\n",
    "# The label encoder is necessary as XGBClassifier expects labels [0,1,2,3] but we have [1,2,3,4]\n",
    "le = LabelEncoder()\n",
    "y_train_ori = le.fit_transform(y_train_ori)\n",
    "y_test_ori = le.fit_transform(y_test_ori)\n",
    "y_train_aug = le.fit_transform(y_train_aug)\n",
    "y_test_aug = le.fit_transform(y_test_aug)\n",
    "\n",
    "# Original dataset\n",
    "xgb_classifier.fit(X_train_ori, y_train_ori)\n",
    "y_pred_ori = xgb_classifier.predict(X_test_ori)\n",
    "print('Original dataset:\\n')\n",
    "print(classification_report(y_test_ori, y_pred_ori))\n",
    "\n",
    "# Augmented dataset\n",
    "xgb_classifier.fit(X_train_combined, y_train_aug)\n",
    "y_pred_aug = xgb_classifier.predict(X_test_combined)\n",
    "print('Augmented dataset:\\n')\n",
    "print(classification_report(y_test_aug, y_pred_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "XGBoost classifier (Sklearn version)\n",
    "As a baseline for the \"random\" f1 score for the original dataset, I trained the XGBoost model on an X_train that was just the length of the text string. This f1 score turned out to be 0.06729. This is expected, and it just means that any meaningful features will produce an F1 score higher than this.<br>\n",
    "Doing the same for the augmented dataset yields an F1 score of 0.1285. This improvement does not necessarily mean that the augmented dataset is \"better\", but rather that this is the base that any meaningful feature needs to beat.\n",
    "\n",
    "We tried converting each of the text into a bag of words vector and training the XGB classifier on it. The f1 score obtained was 0.8765 for the original dataset, with an accuracy of 0.8851 and precision of 0.8935. Doing the same for the augmented dataset, the f1 score obtained was 0.8731, with accuracy 0.8759 and precision 0.8742. Although the model seems to do poorer on the augmented dataset, the discrepancy is minimal.<br>\n",
    "Here, I think it is safe to conclude that when it comes to this particular feature, adding the new rows to the dataset does not affect the performance of the XGBoost classifier model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
