{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Python Notebook to train XGBoost model on both the original and augmented dataset\n",
            "\n",
            "Here, we use the xgboost package but use the classifier built in the package that is built to integrate with sklearn at the cost of some functionality.\n",
            "[Source](https://www.datacamp.com/tutorial/xgboost-in-python)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "#Import necessary modules\n",
            "from sklearn.ensemble import GradientBoostingClassifier\n",
            "from sklearn.feature_extraction.text import CountVectorizer\n",
            "from sklearn.preprocessing import LabelEncoder\n",
            "from sklearn.model_selection import GridSearchCV\n",
            "from sklearn.model_selection import RepeatedKFold\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import classification_report\n",
            "from sklearn.preprocessing import OneHotEncoder\n",
            "from scipy.sparse import hstack, csr_matrix, vstack\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import nltk\n",
            "import xgboost as xgb\n",
            "import matplotlib.pylab as pl\n",
            "import lime\n",
            "import lime.lime_tabular"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Configure NLTK if applicable"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# nltk.download('averaged_perceptron_tagger')\n",
            "# nltk.download('punkt')\n",
            "# nltk.download('wordnet')\n",
            "# nltk.download('vader_lexicon')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # obtained from https://gist.github.com/susanli2016/d35def30b99f0e2f56c0e01e19ad0878\n",
            "# def gettop_n_bigram(corpus, n=None):\n",
            "#     vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n",
            "#     bag_of_words = vec.transform(corpus)\n",
            "#     sum_words = bag_of_words.sum(axis=0)\n",
            "#     words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
            "#     words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
            "#     return words_freq[:n]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_len(row):\n",
            "    return len(row['Text'])\n",
            "\n",
            "def get_len_aug(row):\n",
            "    return len(row['text'])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Perform feature engineering on the dataset\n",
            "def feature_engineering(dataset, aug):\n",
            "    if (aug):\n",
            "        dataset['los'] = dataset.apply(get_len_aug, axis=1)\n",
            "    else:\n",
            "        dataset['los'] = dataset.apply(get_len, axis=1)\n",
            "\n",
            "    # bow_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
            "    # col_name = \"\"\n",
            "    # if aug:\n",
            "    #     col_name = 'text'\n",
            "    # else:\n",
            "    #     col_name = 'Text'\n",
            "    # text_col = dataset[col_name]\n",
            "    # new_col = bow_vectorizer.fit_transform(text_col)\n",
            "    # dataset['bowvec'] = new_col\n",
            "    return dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Add the features has_swear_word, severity, topic to the augmented train set\n",
            "\n",
            "def add_aug_features(dataframe, x_train):\n",
            "    # Prepare a df with only the features we want to OHE\n",
            "    ohe_df = dataframe[['has_swear_word', 'severity', 'topic']]\n",
            "    encoded_df = pd.get_dummies(ohe_df)\n",
            "    encoded_df[:10]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0        1\n",
                     "1        1\n",
                     "2        1\n",
                     "3        1\n",
                     "4        1\n",
                     "        ..\n",
                     "59790    4\n",
                     "59791    4\n",
                     "59792    4\n",
                     "59793    4\n",
                     "59794    4\n",
                     "Name: label, Length: 59795, dtype: int64"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "train_original = pd.read_csv('dataset/fulltrain.csv')\n",
            "train_augment = pd.read_csv('dataset/merged_final_df_with_topics_new.csv')\n",
            "test_original = pd.read_csv('dataset/balancedtest.csv')\n",
            "test_augment = pd.read_csv('dataset/test_final_with_topics_new.csv')\n",
            "\n",
            "bow_vectorizer_ori = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
            "bow_vectorizer_aug = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
            "# X_ori = bow_vectorizer_ori.fit_transform(train_original['Text'])\n",
            "# X_aug = bow_vectorizer_aug.fit_transform(train_augment['text'])\n",
            "\n",
            "# y_ori = train_original['Label']\n",
            "# y_aug = train_augment['label']\n",
            "\n",
            "X_train_ori = bow_vectorizer_ori.fit_transform(train_original['Text'])\n",
            "X_train_aug = bow_vectorizer_aug.fit_transform(train_augment['text'])\n",
            "\n",
            "y_train_ori = train_original['Label']\n",
            "y_train_aug = train_augment['label']\n",
            "\n",
            "X_test_ori = bow_vectorizer_ori.transform(test_original['Text'])\n",
            "X_test_aug = bow_vectorizer_aug.transform(test_augment['text'])\n",
            "\n",
            "y_test_ori = test_original['Label']\n",
            "y_test_aug = test_augment['label']\n",
            "\n",
            "# X_train_ori, X_test_ori, y_train_ori, y_test_ori = train_test_split(X_ori, y_ori, test_size=0.20, random_state=42)\n",
            "# X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(X_aug, y_aug, test_size=0.20, random_state=42)\n",
            "train_augment['label']"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<59795x228982 sparse matrix of type '<class 'numpy.int64'>'\n",
                     "\twith 10614690 stored elements in Compressed Sparse Row format>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "<3000x228982 sparse matrix of type '<class 'numpy.float64'>'\n",
                     "\twith 549286 stored elements in Compressed Sparse Row format>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# ohe_df = train_augment[['has_swear_word', 'severity', 'topic']]\n",
            "encoded_df = pd.get_dummies(train_augment, columns = ['has_swear_word', 'severity', 'topic'])\n",
            "dropped_df = encoded_df.drop(['label', 'text', 'processed_text'], axis=1)\n",
            "sparse = csr_matrix(dropped_df)\n",
            "sparse_2 = csr_matrix(X_train_aug)\n",
            "X_train_combined = hstack([sparse_2, sparse])\n",
            "\n",
            "encoded_df = pd.get_dummies(test_augment, columns = ['has_swear_word', 'severity', 'topic'])\n",
            "dropped_df = encoded_df.drop(['label', 'text', 'processed_text'], axis=1)\n",
            "sparse = csr_matrix(dropped_df)\n",
            "sparse_2 = csr_matrix(X_test_aug)\n",
            "X_test_combined = hstack([sparse_2, sparse])\n",
            "\n",
            "def pad_columns(matrix1, matrix2):\n",
            "    matrix1_rows = matrix1.shape[0]\n",
            "    matrix2_rows = matrix2.shape[0]\n",
            "    matrix1_cols = matrix1.shape[1]\n",
            "    matrix2_cols = matrix2.shape[1]\n",
            "    diff = matrix1_cols - matrix2_cols\n",
            "    if (diff < 0):\n",
            "        # Need to pad columns to matrix 1\n",
            "        diff = diff * -1\n",
            "        zero_matrix = csr_matrix((matrix1_rows, diff))\n",
            "        matrix1 = hstack([matrix1, zero_matrix])\n",
            "    elif (diff > 0):\n",
            "        # Need to pad columns to matrix 2\n",
            "        zero_matrix = csr_matrix((matrix2_rows, diff))\n",
            "        matrix2 = hstack([matrix2, zero_matrix])\n",
            "    return (matrix1, matrix2)\n",
            "\n",
            "X_train_combined, X_test_combined = pad_columns(X_train_combined, X_test_combined)\n",
            "display(X_train_combined)\n",
            "display(X_test_combined)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 164,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(3000, 228864)"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "(59795, 228864)"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "#Run this if you need to modify X_train again for some reason\n",
            "# X_train = train_augment['topic']\n",
            "# print(dropped_df)\n",
            "display(X_test_aug.shape)\n",
            "display(X_train_aug.shape)\n",
            "# print(X_test_ori.shape)\n",
            "# print(train_original[:5])\n",
            "# print(test_original[:5])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "ename": "KeyboardInterrupt",
               "evalue": "",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Hyperparameter tuning for xgb model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# First, we do a train_test_split on the original dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m bow_vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m X_ori \u001b[38;5;241m=\u001b[39m \u001b[43mbow_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_original\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m y_ori \u001b[38;5;241m=\u001b[39m train_original[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_ori, y_ori, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
                  "File \u001b[0;32m~/Desktop/Year_4_Sem_2/CS4248/4248_project_Dissect_LUN/.venv/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/Desktop/Year_4_Sem_2/CS4248/4248_project_Dissect_LUN/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1386\u001b[0m             )\n\u001b[1;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
                  "File \u001b[0;32m~/Desktop/Year_4_Sem_2/CS4248/4248_project_Dissect_LUN/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1275\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1277\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
                  "File \u001b[0;32m~/Desktop/Year_4_Sem_2/CS4248/4248_project_Dissect_LUN/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:112\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    110\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                  "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
               ]
            }
         ],
         "source": [
            "# Hyperparameter tuning for xgb model\n",
            "\n",
            "# First, we do a train_test_split on the original dataset\n",
            "bow_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 1))\n",
            "X_ori = bow_vectorizer.fit_transform(train_original['Text'])\n",
            "y_ori = train_original['Label']\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_ori, y_ori, test_size=0.20, random_state=42)\n",
            "\n",
            "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', tree_method='hist', enable_categorical=True, max_depth=3, n_estimators=500)\n",
            "# params = {'n_estimators': [1, 10, 25, 50, 100, 200], 'eta': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'max_depth': [2, 3, 4, 5, 10, 20]}\n",
            "params = {'n_estimators': [700, 800 ,900]}\n",
            "\n",
            "le = LabelEncoder()\n",
            "y_train = le.fit_transform(y_train)\n",
            "\n",
            "# Yes this is probably not enough, but the dataset is large, and I don't have all day.\n",
            "cv = RepeatedKFold(n_splits=2, n_repeats=1)\n",
            "\n",
            "clf = GridSearchCV(xgb_classifier, params, cv=cv, verbose=2)\n",
            "xgb_opt = clf.fit(X_train, y_train)\n",
            "\n",
            "print(\"optimal_param: \", xgb_opt.best_estimator_.get_params()['n_estimators'])\n",
            "# print(\"optimal_param: \", xgb_opt.best_estimator_.get_params()['eta'])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Hyperparameter tuning notes\n",
            "For the XGBoost model, I decided to stick to tree ensemble methods (might need to justify, but it is the default so it is probably the more general one). Hence, there are 3 main hyperparameters to tune:  \n",
            "1. n_estimators: Number of estimators used in the ensemble model.\n",
            "1. eta: The learning rate.\n",
            "1. max_depth: The maximum depth of each individual tree model.\n",
            "\n",
            "Hyperparameter tuning was done on the training data with an 80:20 test split. Sklearn's GridSearchCV was used to automate the process.\n",
            "In the end, the values of the hyperparameters we arrived at was:\n",
            "1. n_estimators: 700\n",
            "1. eta: 0.5\n",
            "1. max_depth: 5"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Original dataset:\n",
                  "\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           0       0.72      0.69      0.70       750\n",
                  "           1       0.71      0.52      0.60       750\n",
                  "           2       0.55      0.50      0.52       750\n",
                  "           3       0.66      0.92      0.77       750\n",
                  "\n",
                  "    accuracy                           0.66      3000\n",
                  "   macro avg       0.66      0.66      0.65      3000\n",
                  "weighted avg       0.66      0.66      0.65      3000\n",
                  "\n",
                  "Augmented dataset:\n",
                  "\n",
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "           0       0.76      0.68      0.72       750\n",
                  "           1       0.70      0.55      0.61       750\n",
                  "           2       0.48      0.38      0.42       750\n",
                  "           3       0.60      0.92      0.73       750\n",
                  "\n",
                  "    accuracy                           0.63      3000\n",
                  "   macro avg       0.64      0.63      0.62      3000\n",
                  "weighted avg       0.64      0.63      0.62      3000\n",
                  "\n"
               ]
            }
         ],
         "source": [
            "# Tuned model\n",
            "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', tree_method='hist', enable_categorical=True, max_depth = 5, n_estimators=700, eta=0.5)\n",
            "\n",
            "# The label encoder is necessary as XGBClassifier expects labels [0,1,2,3] but we have [1,2,3,4]\n",
            "le = LabelEncoder()\n",
            "y_train_ori = le.fit_transform(y_train_ori)\n",
            "y_test_ori = le.fit_transform(y_test_ori)\n",
            "y_train_aug = le.fit_transform(y_train_aug)\n",
            "y_test_aug = le.fit_transform(y_test_aug)\n",
            "\n",
            "# Original dataset\n",
            "xgb_classifier.fit(X_train_ori, y_train_ori)\n",
            "y_pred_ori = xgb_classifier.predict(X_test_ori)\n",
            "print('Original dataset:\\n')\n",
            "print(classification_report(y_test_ori, y_pred_ori))\n",
            "\n",
            "# Augmented dataset\n",
            "xgb_classifier.fit(X_train_combined, y_train_aug)\n",
            "y_pred_aug = xgb_classifier.predict(X_test_combined)\n",
            "print('Augmented dataset:\\n')\n",
            "print(classification_report(y_test_aug, y_pred_aug))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Notes\n",
            "\n",
            "XGBoost classifier (Sklearn version)\n",
            "As a baseline for the \"random\" f1 score for the original dataset, I trained the XGBoost model on an X_train that was just the length of the text string. This f1 score turned out to be 0.06729. This is expected, and it just means that any meaningful features will produce an F1 score higher than this.<br>\n",
            "Doing the same for the augmented dataset yields an F1 score of 0.1285. This improvement does not necessarily mean that the augmented dataset is \"better\", but rather that this is the base that any meaningful feature needs to beat.\n",
            "\n",
            "We tried converting each of the text into a bag of words vector and training the XGB classifier on it. The f1 score obtained was 0.8765 for the original dataset, with an accuracy of 0.8851 and precision of 0.8935. Doing the same for the augmented dataset, the f1 score obtained was 0.8731, with accuracy 0.8759 and precision 0.8742. Although the model seems to do poorer on the augmented dataset, the discrepancy is minimal.<br>\n",
            "Here, I think it is safe to conclude that when it comes to this particular feature, adding the new rows to the dataset does not affect the performance of the XGBoost classifier model."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 152,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>label</th>\n",
                     "      <th>text</th>\n",
                     "      <th>predicted_label</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>1</td>\n",
                     "      <td>When so many actors seem content to churn out ...</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>1</td>\n",
                     "      <td>In what football insiders are calling an unex...</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>1</td>\n",
                     "      <td>In a freak accident following Game 3 of the N....</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>1</td>\n",
                     "      <td>North Koreas official news agency announced to...</td>\n",
                     "      <td>0</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>1</td>\n",
                     "      <td>The former Alaska Governor Sarah Palin would b...</td>\n",
                     "      <td>3</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2995</th>\n",
                     "      <td>4</td>\n",
                     "      <td>The Air Force mistakenly gave rival companies ...</td>\n",
                     "      <td>3</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2996</th>\n",
                     "      <td>4</td>\n",
                     "      <td>The United Nations climate chief on Friday cha...</td>\n",
                     "      <td>3</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2997</th>\n",
                     "      <td>4</td>\n",
                     "      <td>River Plate midfielder Diego Buonanotte has un...</td>\n",
                     "      <td>3</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2998</th>\n",
                     "      <td>4</td>\n",
                     "      <td>Lawmakers were on the brink Tuesday of exempti...</td>\n",
                     "      <td>3</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2999</th>\n",
                     "      <td>4</td>\n",
                     "      <td>The Pentagon, which is processing bids on a ne...</td>\n",
                     "      <td>3</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>3000 rows Ã— 3 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "      label                                               text  \\\n",
                     "0         1  When so many actors seem content to churn out ...   \n",
                     "1         1   In what football insiders are calling an unex...   \n",
                     "2         1  In a freak accident following Game 3 of the N....   \n",
                     "3         1  North Koreas official news agency announced to...   \n",
                     "4         1  The former Alaska Governor Sarah Palin would b...   \n",
                     "...     ...                                                ...   \n",
                     "2995      4  The Air Force mistakenly gave rival companies ...   \n",
                     "2996      4  The United Nations climate chief on Friday cha...   \n",
                     "2997      4  River Plate midfielder Diego Buonanotte has un...   \n",
                     "2998      4  Lawmakers were on the brink Tuesday of exempti...   \n",
                     "2999      4  The Pentagon, which is processing bids on a ne...   \n",
                     "\n",
                     "      predicted_label  \n",
                     "0                   0  \n",
                     "1                   0  \n",
                     "2                   0  \n",
                     "3                   0  \n",
                     "4                   3  \n",
                     "...               ...  \n",
                     "2995                3  \n",
                     "2996                3  \n",
                     "2997                3  \n",
                     "2998                3  \n",
                     "2999                3  \n",
                     "\n",
                     "[3000 rows x 3 columns]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Generate CSV\n",
            "\n",
            "test_original = pd.read_csv('dataset/balancedtest.csv')\n",
            "test_augment = pd.read_csv('dataset/test_final_with_topics_new.csv')\n",
            "\n",
            "test_original['predicted_label'] = y_pred_ori\n",
            "test_augment['predicted_label'] = y_pred_aug\n",
            "\n",
            "test_augment_dropped = test_augment.drop(['has_swear_word', 'severity', 'processed_text', 'topic'], axis=1)\n",
            "\n",
            "test_original.to_csv('XGBoost_original.csv', index=False)\n",
            "test_augment_dropped.to_csv('XGBoost_augment.csv', index=False)\n",
            "\n",
            "display(test_augment_dropped)\n",
            "\n",
            "# print(len(y_pred_ori))\n",
            "# print(len(y_pred_aug))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Downsample because shap was crashing my kernel\n",
            "X_train_part = X_train_ori[:1000]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "array([2716, 2701, 2970, 2997, 2918])"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "array([12, 32, 33, 34, 35])"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Interpretability of the model using LIME\n",
            "\n",
            "errors = y_pred_ori - y_test_ori\n",
            "sorted_errors = np.argsort(abs(errors))\n",
            "worse_5 = sorted_errors[-5:]\n",
            "best_5 = sorted_errors[:5]\n",
            "display(worse_5)\n",
            "display(best_5)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.0"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
